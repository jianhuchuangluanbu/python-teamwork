{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "第三部分",
   "id": "f20e9ab538ff2db7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "NLTK中的nltk.tokenize模块\n",
    "\n",
    "nltk.tokenize模块专门用于分词，即将文本拆分成单词、句子或其他标记的过程。"
   ],
   "id": "5e10f66825a3ef84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. word_tokenize\n",
    "\n",
    "word_tokenize函数可以将字符串分割成单词列表，分词的目的是将一段连续的文本分解为更小的单位，以便于后续的分析和处理。\n",
    "\n",
    "使用前需要先下载punkt模型\n",
    "\n",
    "Punkt模型是一个基于无监督学习的句子边界检测工具，专门用于句子分割"
   ],
   "id": "667718ad2fdb9f0f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b9f8b320a021b9a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T06:48:44.162746Z",
     "start_time": "2024-06-16T06:48:43.529665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ],
   "id": "ba01513c9f0efbc9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Honjoutx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "测试用例",
   "id": "3209c96be61d67e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T06:59:39.714511Z",
     "start_time": "2024-06-16T06:59:39.711428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cases = [\n",
    "    {\n",
    "        \"text\": \"The international community must continue to pay close attention to the troubling human rights situation in the Democratic People’s Republic of Korea (DPRK) and find ways to revive dialogue with the Government, the UN Security Council heard on Wednesday. \"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"China and Russia opposed the meeting and called for a procedural vote by the 15 members, which was defeated. \"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"One consequence is that divided families are even more divided. No departures means no reunification with families abroad.\"\n",
    "    }\n",
    "]"
   ],
   "id": "7248357383c08f26",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:12:49.057257Z",
     "start_time": "2024-06-14T11:12:49.049543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for case in cases:\n",
    "    text = case[\"text\"]\n",
    "    result = word_tokenize(text)\n",
    "    print(result)"
   ],
   "id": "ab52b36a1b1d7cb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'international', 'community', 'must', 'continue', 'to', 'pay', 'close', 'attention', 'to', 'the', 'troubling', 'human', 'rights', 'situation', 'in', 'the', 'Democratic', 'People', '’', 's', 'Republic', 'of', 'Korea', '(', 'DPRK', ')', 'and', 'find', 'ways', 'to', 'revive', 'dialogue', 'with', 'the', 'Government', ',', 'the', 'UN', 'Security', 'Council', 'heard', 'on', 'Wednesday', '.']\n",
      "['China', 'and', 'Russia', 'opposed', 'the', 'meeting', 'and', 'called', 'for', 'a', 'procedural', 'vote', 'by', 'the', '15', 'members', ',', 'which', 'was', 'defeated', '.']\n",
      "['One', 'consequence', 'is', 'that', 'divided', 'families', 'are', 'even', 'more', 'divided', '.', 'No', 'departures', 'means', 'no', 'reunification', 'with', 'families', 'abroad', '.']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T06:49:22.956773Z",
     "start_time": "2024-06-16T06:49:22.953504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "for case in cases:\n",
    "    text = case[\"text\"]\n",
    "    result = word_tokenize(text)\n",
    "    word_freq = Counter(result)\n",
    "    print(word_freq)\n"
   ],
   "id": "89843febb99016c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'the': 4, 'to': 3, 'The': 1, 'international': 1, 'community': 1, 'must': 1, 'continue': 1, 'pay': 1, 'close': 1, 'attention': 1, 'troubling': 1, 'human': 1, 'rights': 1, 'situation': 1, 'in': 1, 'Democratic': 1, 'People': 1, '’': 1, 's': 1, 'Republic': 1, 'of': 1, 'Korea': 1, '(': 1, 'DPRK': 1, ')': 1, 'and': 1, 'find': 1, 'ways': 1, 'revive': 1, 'dialogue': 1, 'with': 1, 'Government': 1, ',': 1, 'UN': 1, 'Security': 1, 'Council': 1, 'heard': 1, 'on': 1, 'Wednesday': 1, '.': 1})\n",
      "Counter({'and': 2, 'the': 2, 'China': 1, 'Russia': 1, 'opposed': 1, 'meeting': 1, 'called': 1, 'for': 1, 'a': 1, 'procedural': 1, 'vote': 1, 'by': 1, '15': 1, 'members': 1, ',': 1, 'which': 1, 'was': 1, 'defeated': 1, '.': 1})\n",
      "Counter({'divided': 2, 'families': 2, '.': 2, 'One': 1, 'consequence': 1, 'is': 1, 'that': 1, 'are': 1, 'even': 1, 'more': 1, 'No': 1, 'departures': 1, 'means': 1, 'no': 1, 'reunification': 1, 'with': 1, 'abroad': 1})\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T06:59:29.050626Z",
     "start_time": "2024-06-16T06:59:28.566708Z"
    }
   },
   "cell_type": "code",
   "source": "nltk.download('stopwords')",
   "id": "190596286a8b0737",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Honjoutx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T07:01:19.799134Z",
     "start_time": "2024-06-16T07:01:19.790340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "for case in cases:\n",
    "    text = case[\"text\"]\n",
    "    result = word_tokenize(text) \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered = [word for word in result if word.lower() not in stop_words and word.isalnum()]\n",
    "    freq = Counter(filtered)\n",
    "\n",
    "keywords = freq.most_common(5)\n",
    "print(f\"Keywords: {keywords}\")\n",
    "\n"
   ],
   "id": "bebd436c114d6db1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords: [('divided', 2), ('families', 2), ('One', 1), ('consequence', 1), ('even', 1)]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "2. sent_tokenize\n",
    "\n",
    "sent_tokenize用于将文本分割成句子列表。句子分割的目的是将一段连续的文本分解为单独的句子，以便于后续的分析和处理。"
   ],
   "id": "5e34b7d60fc34126"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:17:28.345137Z",
     "start_time": "2024-06-14T11:17:28.343203Z"
    }
   },
   "cell_type": "code",
   "source": "from nltk.tokenize import sent_tokenize",
   "id": "dee4404a5d0e1db0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "测试用例",
   "id": "ca49b5a27c15cfc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:17:29.915576Z",
     "start_time": "2024-06-14T11:17:29.913191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cases = [\n",
    "    {\n",
    "        \"text\": \"The international community must continue to pay close attention to the troubling human rights situation in the Democratic People’s Republic of Korea (DPRK) and find ways to revive dialogue with the Government, the UN Security Council heard on Wednesday. \"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Born to a leading family in the capital, Pyongyang, Mr. Kim was 19 when he left to study in Beijing in 2010. Using the internet, he said he learned about his homeland and “the horrific truth” previously hidden to him.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"He too welcomed the OECD figures announced on Wednesday and said there is now an opportunity to consider what the transition to renewable energy really means for SIDS. It amounts to economic transformation, he said.\"\n",
    "    }\n",
    "]\n"
   ],
   "id": "432cdf82468369a8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:17:31.122505Z",
     "start_time": "2024-06-14T11:17:31.119522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for case in cases:\n",
    "    text = case[\"text\"]\n",
    "    result = sent_tokenize(text)\n",
    "    print(result)"
   ],
   "id": "4165e2144a63e76e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The international community must continue to pay close attention to the troubling human rights situation in the Democratic People’s Republic of Korea (DPRK) and find ways to revive dialogue with the Government, the UN Security Council heard on Wednesday.']\n",
      "['Born to a leading family in the capital, Pyongyang, Mr. Kim was 19 when he left to study in Beijing in 2010.', 'Using the internet, he said he learned about his homeland and “the horrific truth” previously hidden to him.']\n",
      "['He too welcomed the OECD figures announced on Wednesday and said there is now an opportunity to consider what the transition to renewable energy really means for SIDS.', 'It amounts to economic transformation, he said.']\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T07:18:10.698008Z",
     "start_time": "2024-06-16T07:18:09.452109Z"
    }
   },
   "cell_type": "code",
   "source": "nltk.download('averaged_perceptron_tagger')",
   "id": "7f2d5451202a4313",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Honjoutx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "句子单词词性标注",
   "id": "656966077e490006"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T07:20:04.495737Z",
     "start_time": "2024-06-16T07:20:04.432740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "for case in cases:\n",
    "    text = case[\"text\"]\n",
    "    result = sent_tokenize(text)\n",
    "    tagged_sentences = [pos_tag(word_tokenize(sentence)) for sentence in result]\n",
    "    for i, tagged_sentence in enumerate(tagged_sentences, start=1):\n",
    "        print(f\"Sentence {i}: {tagged_sentence}\\n\")\n"
   ],
   "id": "14b9c38d7c87545",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: [('The', 'DT'), ('international', 'JJ'), ('community', 'NN'), ('must', 'MD'), ('continue', 'VB'), ('to', 'TO'), ('pay', 'VB'), ('close', 'JJ'), ('attention', 'NN'), ('to', 'TO'), ('the', 'DT'), ('troubling', 'VBG'), ('human', 'JJ'), ('rights', 'NNS'), ('situation', 'NN'), ('in', 'IN'), ('the', 'DT'), ('Democratic', 'JJ'), ('People', 'NNP'), ('’', 'NNP'), ('s', 'VBZ'), ('Republic', 'NNP'), ('of', 'IN'), ('Korea', 'NNP'), ('(', '('), ('DPRK', 'NNP'), (')', ')'), ('and', 'CC'), ('find', 'VBP'), ('ways', 'NNS'), ('to', 'TO'), ('revive', 'VB'), ('dialogue', 'NN'), ('with', 'IN'), ('the', 'DT'), ('Government', 'NNP'), (',', ','), ('the', 'DT'), ('UN', 'NNP'), ('Security', 'NNP'), ('Council', 'NNP'), ('heard', 'NN'), ('on', 'IN'), ('Wednesday', 'NNP'), ('.', '.')]\n",
      "\n",
      "Sentence 1: [('China', 'NNP'), ('and', 'CC'), ('Russia', 'NNP'), ('opposed', 'VBD'), ('the', 'DT'), ('meeting', 'NN'), ('and', 'CC'), ('called', 'VBD'), ('for', 'IN'), ('a', 'DT'), ('procedural', 'JJ'), ('vote', 'NN'), ('by', 'IN'), ('the', 'DT'), ('15', 'CD'), ('members', 'NNS'), (',', ','), ('which', 'WDT'), ('was', 'VBD'), ('defeated', 'VBN'), ('.', '.')]\n",
      "\n",
      "Sentence 1: [('One', 'CD'), ('consequence', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('divided', 'JJ'), ('families', 'NNS'), ('are', 'VBP'), ('even', 'RB'), ('more', 'RBR'), ('divided', 'JJ'), ('.', '.')]\n",
      "\n",
      "Sentence 2: [('No', 'DT'), ('departures', 'NNS'), ('means', 'VBZ'), ('no', 'DT'), ('reunification', 'NN'), ('with', 'IN'), ('families', 'NNS'), ('abroad', 'RB'), ('.', '.')]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "分句拼写纠正",
   "id": "55957bc9c93cbf3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T07:28:44.153097Z",
     "start_time": "2024-06-16T07:28:44.103454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from autocorrect import Speller\n",
    "\n",
    "spell = Speller()\n",
    "sentences = []\n",
    "for case in cases:\n",
    "    text = case[\"text\"]\n",
    "    result = sent_tokenize(text)\n",
    "    for sentence in result :\n",
    "        words = sentence.split()\n",
    "        corrected_words = [spell(word) for word in words]\n",
    "        corrected_sentence = ' '.join(corrected_words)\n",
    "        sentences.append(corrected_sentence)\n",
    "        corrected_text = ' '.join(sentences)\n",
    "        print(f\"corrected: {corrected_text}\")\n",
    "\n"
   ],
   "id": "2dc5d7c3f6f8321d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrected: The international community must continue to pay close attention to the troubling human rights situation in the Democratic People’s Republic of Korea (PRK) and find ways to revive dialogue with the Government, the Up Security Council heard on Wednesday.\n",
      "corrected: The international community must continue to pay close attention to the troubling human rights situation in the Democratic People’s Republic of Korea (PRK) and find ways to revive dialogue with the Government, the Up Security Council heard on Wednesday. China and Russia opposed the meeting and called for a procedural vote by the 15 members, which was defeated.\n",
      "corrected: The international community must continue to pay close attention to the troubling human rights situation in the Democratic People’s Republic of Korea (PRK) and find ways to revive dialogue with the Government, the Up Security Council heard on Wednesday. China and Russia opposed the meeting and called for a procedural vote by the 15 members, which was defeated. One consequence is that divided families are even more divided.\n",
      "corrected: The international community must continue to pay close attention to the troubling human rights situation in the Democratic People’s Republic of Korea (PRK) and find ways to revive dialogue with the Government, the Up Security Council heard on Wednesday. China and Russia opposed the meeting and called for a procedural vote by the 15 members, which was defeated. One consequence is that divided families are even more divided. No departures means no reunification with families abroad.\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3. RegexpTokenizer\n",
    "\n",
    "RegexpTokenizer用于基于正则表达式进行分词。与word_tokenize和sent_tokenize等函数不同，RegexpTokenizer允许用户使用自定义的正则表达式来定义分词规则，从而实现更灵活和精确的分词。"
   ],
   "id": "4ebcf20f5f7ced16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T07:36:21.352535Z",
     "start_time": "2024-06-16T07:36:21.349354Z"
    }
   },
   "cell_type": "code",
   "source": "from nltk.tokenize import RegexpTokenizer",
   "id": "eeba9374f30a7c7d",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "测试用例",
   "id": "ea9006ecc8202c6c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:23:32.725939Z",
     "start_time": "2024-06-14T11:23:32.722684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cases = [\n",
    "    {\n",
    "        \"text\": \"The international community must continue to pay close attention to the troubling human rights situation in the Democratic People’s Republic of Korea (DPRK) and find ways to revive dialogue with the Government, the UN Security Council heard on Wednesday. \"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Born to a leading family in the capital, Pyongyang, Mr. Kim was 19 when he left to study in Beijing in 2010. Using the internet, he said he learned about his homeland and “the horrific truth” previously hidden to him.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"He too welcomed the OECD figures announced on Wednesday and said there is now an opportunity to consider what the transition to renewable energy really means for SIDS. It amounts to economic transformation, he said.\"\n",
    "    }\n",
    "]"
   ],
   "id": "6fdd4e4ffd83a4dc",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "定义正则表达式，只保留单词",
   "id": "6639cd0f144aa6cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T12:33:44.000099Z",
     "start_time": "2024-06-14T12:33:43.997992Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = RegexpTokenizer(r'\\w+')",
   "id": "10a58cf42402cb6c",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T12:33:44.809091Z",
     "start_time": "2024-06-14T12:33:44.806438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for case in cases:\n",
    "    text = case[\"text\"]\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    print(tokens)"
   ],
   "id": "e1daf2c219b45da4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'international', 'community', 'must', 'continue', 'to', 'pay', 'close', 'attention', 'to', 'the', 'troubling', 'human', 'rights', 'situation', 'in', 'the', 'Democratic', 'People', 's', 'Republic', 'of', 'Korea', 'DPRK', 'and', 'find', 'ways', 'to', 'revive', 'dialogue', 'with', 'the', 'Government', 'the', 'UN', 'Security', 'Council', 'heard', 'on', 'Wednesday']\n",
      "['Born', 'to', 'a', 'leading', 'family', 'in', 'the', 'capital', 'Pyongyang', 'Mr', 'Kim', 'was', '19', 'when', 'he', 'left', 'to', 'study', 'in', 'Beijing', 'in', '2010', 'Using', 'the', 'internet', 'he', 'said', 'he', 'learned', 'about', 'his', 'homeland', 'and', 'the', 'horrific', 'truth', 'previously', 'hidden', 'to', 'him']\n",
      "['He', 'too', 'welcomed', 'the', 'OECD', 'figures', 'announced', 'on', 'Wednesday', 'and', 'said', 'there', 'is', 'now', 'an', 'opportunity', 'to', 'consider', 'what', 'the', 'transition', 'to', 'renewable', 'energy', 'really', 'means', 'for', 'SIDS', 'It', 'amounts', 'to', 'economic', 'transformation', 'he', 'said']\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "定义正则表达式，保留单词和标点符号",
   "id": "bab333c847385aad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T12:33:46.336677Z",
     "start_time": "2024-06-14T12:33:46.334172Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = RegexpTokenizer(r'\\w+|[^\\w\\s]')",
   "id": "61861423630f9854",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T12:33:47.028590Z",
     "start_time": "2024-06-14T12:33:47.025446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for case in cases:\n",
    "    text = case[\"text\"]\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    print(tokens)"
   ],
   "id": "b9788eb2bde6cb21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'international', 'community', 'must', 'continue', 'to', 'pay', 'close', 'attention', 'to', 'the', 'troubling', 'human', 'rights', 'situation', 'in', 'the', 'Democratic', 'People', '’', 's', 'Republic', 'of', 'Korea', '(', 'DPRK', ')', 'and', 'find', 'ways', 'to', 'revive', 'dialogue', 'with', 'the', 'Government', ',', 'the', 'UN', 'Security', 'Council', 'heard', 'on', 'Wednesday', '.']\n",
      "['Born', 'to', 'a', 'leading', 'family', 'in', 'the', 'capital', ',', 'Pyongyang', ',', 'Mr', '.', 'Kim', 'was', '19', 'when', 'he', 'left', 'to', 'study', 'in', 'Beijing', 'in', '2010', '.', 'Using', 'the', 'internet', ',', 'he', 'said', 'he', 'learned', 'about', 'his', 'homeland', 'and', '“', 'the', 'horrific', 'truth', '”', 'previously', 'hidden', 'to', 'him', '.']\n",
      "['He', 'too', 'welcomed', 'the', 'OECD', 'figures', 'announced', 'on', 'Wednesday', 'and', 'said', 'there', 'is', 'now', 'an', 'opportunity', 'to', 'consider', 'what', 'the', 'transition', 'to', 'renewable', 'energy', 'really', 'means', 'for', 'SIDS', '.', 'It', 'amounts', 'to', 'economic', 'transformation', ',', 'he', 'said', '.']\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T07:36:45.546047Z",
     "start_time": "2024-06-16T07:36:45.543047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cases = \"Contact us at support@example.com, sales@example.com, or info@example.com.\"\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b')\n",
    "tokens = tokenizer.tokenize(cases)\n",
    "\n",
    "print(tokens)\n"
   ],
   "id": "b654a103a9c190ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['support@example.com', 'sales@example.com', 'info@example.com']\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "4. TreebankWordTokenizer\n",
    "\n",
    "\n",
    "TreebankWordTokenizer是一种基于宾州树库中使用的分词标准而设计的用于自然语言处理的分词器，用于将英语文本分割成单词和标点符号。这种分词器在处理标点符号、缩略词、连字符等方面具有特定的规则。"
   ],
   "id": "70daf776939b1409"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T07:43:53.572492Z",
     "start_time": "2024-06-16T07:43:53.570298Z"
    }
   },
   "cell_type": "code",
   "source": "from nltk.tokenize import TreebankWordTokenizer",
   "id": "dab87f2183423625",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "测试用例",
   "id": "bd22ebc4041d7a66"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T07:43:54.540359Z",
     "start_time": "2024-06-16T07:43:54.537854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cases = [\n",
    "    {\n",
    "        \"text\": \"Born to a leading family in the capital, Pyongyang, Mr. Kim was 19 when he left to study in Beijing in 2010. Using the internet, he said he learned about his homeland and “the horrific truth” previously hidden to him.\"\n",
    "    },\n",
    "]"
   ],
   "id": "ed3119c1b322933d",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "文本预处理",
   "id": "51999e5518d70995"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T07:43:56.341860Z",
     "start_time": "2024-06-16T07:43:56.339415Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = TreebankWordTokenizer()",
   "id": "c265f4f69206cebb",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T07:43:57.311163Z",
     "start_time": "2024-06-16T07:43:57.308166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = cases[0][\"text\"]\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)"
   ],
   "id": "a4fac027b1bafae2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Born', 'to', 'a', 'leading', 'family', 'in', 'the', 'capital', ',', 'Pyongyang', ',', 'Mr.', 'Kim', 'was', '19', 'when', 'he', 'left', 'to', 'study', 'in', 'Beijing', 'in', '2010.', 'Using', 'the', 'internet', ',', 'he', 'said', 'he', 'learned', 'about', 'his', 'homeland', 'and', '“the', 'horrific', 'truth”', 'previously', 'hidden', 'to', 'him', '.']\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "情感分析\n",
    "\n",
    "通过分词提高识别准确性\n",
    "\n",
    "需要额外使用到nltk.sentiment.vader库"
   ],
   "id": "e874095ac82c670a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T07:41:30.369655Z",
     "start_time": "2024-06-16T07:41:29.483558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ],
   "id": "bf200b931d19f1ab",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Honjoutx\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T07:43:59.825589Z",
     "start_time": "2024-06-16T07:43:59.818765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "target_text = \" \".join(tokens)\n",
    "sentiment = analyzer.polarity_scores(target_text)\n",
    "print(sentiment)"
   ],
   "id": "300a7419eab8ed45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.104, 'neu': 0.896, 'pos': 0.0, 'compound': -0.6597}\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "机器翻译\n",
    "\n",
    "作为预处理步骤包括将源语言文本分割成单词，然后进行翻译"
   ],
   "id": "8f10718c095b2f04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T07:46:03.891738Z",
     "start_time": "2024-06-16T07:46:03.891738Z"
    }
   },
   "cell_type": "code",
   "source": "from googletrans import Translator",
   "id": "40f9462fbb31ee99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T07:46:03.890719Z",
     "start_time": "2024-06-16T07:45:53.570122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "translator = Translator()\n",
    "text = cases[0][\"text\"]\n",
    "tokens = tokenizer.tokenize(text)\n",
    "translated_tokens = [translator.translate(word, src='en', dest='es').text for word in tokens]\n",
    "translate = ' '.join(translated_tokens)\n",
    "print(f\"Translated Text: {translate}\")"
   ],
   "id": "5b1b014da528a086",
   "outputs": [
    {
     "ename": "ConnectTimeout",
     "evalue": "timed out",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mConnectTimeout\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[45], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m text \u001B[38;5;241m=\u001B[39m cases[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m      4\u001B[0m tokens \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mtokenize(text)\n\u001B[1;32m----> 5\u001B[0m translated_tokens \u001B[38;5;241m=\u001B[39m [\u001B[43mtranslator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranslate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mword\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43men\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mes\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtext \u001B[38;5;28;01mfor\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m tokens]\n\u001B[0;32m      6\u001B[0m translate \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(translated_tokens)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTranslated Text: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtranslate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\python_final\\.venv\\Lib\\site-packages\\googletrans\\client.py:182\u001B[0m, in \u001B[0;36mTranslator.translate\u001B[1;34m(self, text, dest, src, **kwargs)\u001B[0m\n\u001B[0;32m    179\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[0;32m    181\u001B[0m origin \u001B[38;5;241m=\u001B[39m text\n\u001B[1;32m--> 182\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_translate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    184\u001B[0m \u001B[38;5;66;03m# this code will be updated when the format is changed.\u001B[39;00m\n\u001B[0;32m    185\u001B[0m translated \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([d[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m d[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m data[\u001B[38;5;241m0\u001B[39m]])\n",
      "File \u001B[1;32m~\\PycharmProjects\\python_final\\.venv\\Lib\\site-packages\\googletrans\\client.py:78\u001B[0m, in \u001B[0;36mTranslator._translate\u001B[1;34m(self, text, dest, src, override)\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_translate\u001B[39m(\u001B[38;5;28mself\u001B[39m, text, dest, src, override):\n\u001B[1;32m---> 78\u001B[0m     token \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtoken_acquirer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     79\u001B[0m     params \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mbuild_params(query\u001B[38;5;241m=\u001B[39mtext, src\u001B[38;5;241m=\u001B[39msrc, dest\u001B[38;5;241m=\u001B[39mdest,\n\u001B[0;32m     80\u001B[0m                                 token\u001B[38;5;241m=\u001B[39mtoken, override\u001B[38;5;241m=\u001B[39moverride)\n\u001B[0;32m     82\u001B[0m     url \u001B[38;5;241m=\u001B[39m urls\u001B[38;5;241m.\u001B[39mTRANSLATE\u001B[38;5;241m.\u001B[39mformat(host\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pick_service_url())\n",
      "File \u001B[1;32m~\\PycharmProjects\\python_final\\.venv\\Lib\\site-packages\\googletrans\\gtoken.py:194\u001B[0m, in \u001B[0;36mTokenAcquirer.do\u001B[1;34m(self, text)\u001B[0m\n\u001B[0;32m    193\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdo\u001B[39m(\u001B[38;5;28mself\u001B[39m, text):\n\u001B[1;32m--> 194\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    195\u001B[0m     tk \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39macquire(text)\n\u001B[0;32m    196\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tk\n",
      "File \u001B[1;32m~\\PycharmProjects\\python_final\\.venv\\Lib\\site-packages\\googletrans\\gtoken.py:54\u001B[0m, in \u001B[0;36mTokenAcquirer._update\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtkk \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtkk\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m==\u001B[39m now:\n\u001B[0;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m---> 54\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhost\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m raw_tkk \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mRE_TKK\u001B[38;5;241m.\u001B[39msearch(r\u001B[38;5;241m.\u001B[39mtext)\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m raw_tkk:\n",
      "File \u001B[1;32m~\\PycharmProjects\\python_final\\.venv\\Lib\\site-packages\\httpx\\_client.py:755\u001B[0m, in \u001B[0;36mClient.get\u001B[1;34m(self, url, params, headers, cookies, auth, allow_redirects, timeout)\u001B[0m\n\u001B[0;32m    744\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\n\u001B[0;32m    745\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    746\u001B[0m     url: URLTypes,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    753\u001B[0m     timeout: typing\u001B[38;5;241m.\u001B[39mUnion[TimeoutTypes, UnsetType] \u001B[38;5;241m=\u001B[39m UNSET,\n\u001B[0;32m    754\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Response:\n\u001B[1;32m--> 755\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    756\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mGET\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    757\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    758\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    759\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    760\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcookies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcookies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    761\u001B[0m \u001B[43m        \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    762\u001B[0m \u001B[43m        \u001B[49m\u001B[43mallow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    763\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    764\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\python_final\\.venv\\Lib\\site-packages\\httpx\\_client.py:600\u001B[0m, in \u001B[0;36mClient.request\u001B[1;34m(self, method, url, data, files, json, params, headers, cookies, auth, allow_redirects, timeout)\u001B[0m\n\u001B[0;32m    575\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[0;32m    576\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    577\u001B[0m     method: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    588\u001B[0m     timeout: typing\u001B[38;5;241m.\u001B[39mUnion[TimeoutTypes, UnsetType] \u001B[38;5;241m=\u001B[39m UNSET,\n\u001B[0;32m    589\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Response:\n\u001B[0;32m    590\u001B[0m     request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuild_request(\n\u001B[0;32m    591\u001B[0m         method\u001B[38;5;241m=\u001B[39mmethod,\n\u001B[0;32m    592\u001B[0m         url\u001B[38;5;241m=\u001B[39murl,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    598\u001B[0m         cookies\u001B[38;5;241m=\u001B[39mcookies,\n\u001B[0;32m    599\u001B[0m     )\n\u001B[1;32m--> 600\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    601\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_redirects\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    602\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\python_final\\.venv\\Lib\\site-packages\\httpx\\_client.py:620\u001B[0m, in \u001B[0;36mClient.send\u001B[1;34m(self, request, stream, auth, allow_redirects, timeout)\u001B[0m\n\u001B[0;32m    616\u001B[0m timeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(timeout, UnsetType) \u001B[38;5;28;01melse\u001B[39;00m Timeout(timeout)\n\u001B[0;32m    618\u001B[0m auth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuild_auth(request, auth)\n\u001B[1;32m--> 620\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_handling_redirects\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    621\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    622\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    624\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n\u001B[0;32m    625\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\python_final\\.venv\\Lib\\site-packages\\httpx\\_client.py:647\u001B[0m, in \u001B[0;36mClient.send_handling_redirects\u001B[1;34m(self, request, auth, timeout, allow_redirects, history)\u001B[0m\n\u001B[0;32m    644\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(history) \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_redirects:\n\u001B[0;32m    645\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m TooManyRedirects()\n\u001B[1;32m--> 647\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_handling_auth\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    648\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhistory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhistory\u001B[49m\n\u001B[0;32m    649\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    650\u001B[0m response\u001B[38;5;241m.\u001B[39mhistory \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(history)\n\u001B[0;32m    652\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m response\u001B[38;5;241m.\u001B[39mis_redirect:\n",
      "File \u001B[1;32m~\\PycharmProjects\\python_final\\.venv\\Lib\\site-packages\\httpx\\_client.py:684\u001B[0m, in \u001B[0;36mClient.send_handling_auth\u001B[1;34m(self, request, history, auth, timeout)\u001B[0m\n\u001B[0;32m    682\u001B[0m request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(auth_flow)\n\u001B[0;32m    683\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 684\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_single_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    685\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m auth\u001B[38;5;241m.\u001B[39mrequires_response_body:\n\u001B[0;32m    686\u001B[0m         response\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[1;32m~\\PycharmProjects\\python_final\\.venv\\Lib\\site-packages\\httpx\\_client.py:714\u001B[0m, in \u001B[0;36mClient.send_single_request\u001B[1;34m(self, request, timeout)\u001B[0m\n\u001B[0;32m    705\u001B[0m transport \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransport_for_url(request\u001B[38;5;241m.\u001B[39murl)\n\u001B[0;32m    707\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    708\u001B[0m     (\n\u001B[0;32m    709\u001B[0m         http_version,\n\u001B[0;32m    710\u001B[0m         status_code,\n\u001B[0;32m    711\u001B[0m         reason_phrase,\n\u001B[0;32m    712\u001B[0m         headers,\n\u001B[0;32m    713\u001B[0m         stream,\n\u001B[1;32m--> 714\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[43mtransport\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    715\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    716\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    717\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    718\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    719\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    720\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    721\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m HTTPError \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m    722\u001B[0m     \u001B[38;5;66;03m# Add the original request to any HTTPError unless\u001B[39;00m\n\u001B[0;32m    723\u001B[0m     \u001B[38;5;66;03m# there'a already a request attached in the case of\u001B[39;00m\n\u001B[0;32m    724\u001B[0m     \u001B[38;5;66;03m# a ProxyError.\u001B[39;00m\n\u001B[0;32m    725\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m exc\u001B[38;5;241m.\u001B[39m_request \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\python_final\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:152\u001B[0m, in \u001B[0;36mSyncConnectionPool.request\u001B[1;34m(self, method, url, headers, stream, timeout)\u001B[0m\n\u001B[0;32m    149\u001B[0m         logger\u001B[38;5;241m.\u001B[39mtrace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreuse connection=\u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, connection)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 152\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    153\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m NewConnectionRequired:\n\u001B[0;32m    156\u001B[0m     connection \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\python_final\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py:65\u001B[0m, in \u001B[0;36mSyncHTTPConnection.request\u001B[1;34m(self, method, url, headers, stream, timeout)\u001B[0m\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msocket:\n\u001B[0;32m     62\u001B[0m         logger\u001B[38;5;241m.\u001B[39mtrace(\n\u001B[0;32m     63\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mopen_socket origin=\u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m timeout=\u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39morigin, timeout\n\u001B[0;32m     64\u001B[0m         )\n\u001B[1;32m---> 65\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msocket \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open_socket\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_connection(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msocket)\n\u001B[0;32m     67\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;129;01min\u001B[39;00m (ConnectionState\u001B[38;5;241m.\u001B[39mREADY, ConnectionState\u001B[38;5;241m.\u001B[39mIDLE):\n",
      "File \u001B[1;32m~\\PycharmProjects\\python_final\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py:85\u001B[0m, in \u001B[0;36mSyncHTTPConnection._open_socket\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m     83\u001B[0m ssl_context \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mssl_context \u001B[38;5;28;01mif\u001B[39;00m scheme \u001B[38;5;241m==\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 85\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen_tcp_stream\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     86\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhostname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mport\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mssl_context\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\n\u001B[0;32m     87\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     88\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m     89\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconnect_failed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\python_final\\.venv\\Lib\\site-packages\\httpcore\\_backends\\sync.py:133\u001B[0m, in \u001B[0;36mSyncBackend.open_tcp_stream\u001B[1;34m(self, hostname, port, ssl_context, timeout)\u001B[0m\n\u001B[0;32m    130\u001B[0m connect_timeout \u001B[38;5;241m=\u001B[39m timeout\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconnect\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    131\u001B[0m exc_map \u001B[38;5;241m=\u001B[39m {socket\u001B[38;5;241m.\u001B[39mtimeout: ConnectTimeout, socket\u001B[38;5;241m.\u001B[39merror: ConnectError}\n\u001B[1;32m--> 133\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmap_exceptions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexc_map\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m    134\u001B[0m \u001B[43m    \u001B[49m\u001B[43msock\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43msocket\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_connection\u001B[49m\u001B[43m(\u001B[49m\u001B[43maddress\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconnect_timeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mssl_context\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m:\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__exit__\u001B[1;34m(self, typ, value, traceback)\u001B[0m\n\u001B[0;32m    156\u001B[0m     value \u001B[38;5;241m=\u001B[39m typ()\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 158\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mthrow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m    160\u001B[0m     \u001B[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001B[39;00m\n\u001B[0;32m    161\u001B[0m     \u001B[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001B[39;00m\n\u001B[0;32m    162\u001B[0m     \u001B[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001B[39;00m\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m exc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m value\n",
      "File \u001B[1;32m~\\PycharmProjects\\python_final\\.venv\\Lib\\site-packages\\httpcore\\_exceptions.py:12\u001B[0m, in \u001B[0;36mmap_exceptions\u001B[1;34m(map)\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m from_exc, to_exc \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mmap\u001B[39m\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(exc, from_exc):\n\u001B[1;32m---> 12\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m to_exc(exc) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[1;31mConnectTimeout\u001B[0m: timed out"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "5. TweetTokenizer\n",
    "\n",
    "TweetTokenizer是一个专门用于处理推文的分词器。它设计用来处理推文中特有的文本格式，比如表情符号、哈希标签、用户提及、URL等。"
   ],
   "id": "1e458e39069fe839"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T06:11:35.018960Z",
     "start_time": "2024-06-16T06:11:35.016532Z"
    }
   },
   "cell_type": "code",
   "source": "from nltk.tokenize import TweetTokenizer",
   "id": "53221482bf9096bc",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "测试用例",
   "id": "590bc1ecf5e9881a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T06:12:41.628122Z",
     "start_time": "2024-06-16T06:12:41.626049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cases = [\n",
    "    \"Thanks for the support, @user1! #grateful\",\n",
    "    \"Had a great time with @user2 and @user3 yesterday! #friends\",\n",
    "    \"Shoutout to @user4 for the amazing work! #appreciation\"\n",
    "]"
   ],
   "id": "68ea25f3c246c1d6",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "话题提取",
   "id": "1776cb692d1a3bb8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T06:11:37.344597Z",
     "start_time": "2024-06-16T06:11:37.341585Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = TweetTokenizer()",
   "id": "c143db33afa803e7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T06:12:43.508365Z",
     "start_time": "2024-06-16T06:12:43.504886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tags = []\n",
    "for tweet in cases:\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    tags.extend([token for token in tokens if token.startswith('#')])\n",
    "\n",
    "print(\"tags:\", tags)"
   ],
   "id": "2cccd127e171a8f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags: ['#grateful', '#friends', '#appreciation']\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "用户提及分析",
   "id": "2a73c51ebef1716b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T06:13:36.156982Z",
     "start_time": "2024-06-16T06:13:36.154683Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = TweetTokenizer()",
   "id": "2bd519db5741cb42",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T06:13:37.103129Z",
     "start_time": "2024-06-16T06:13:37.099720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "users = []\n",
    "for tweet in cases:\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    users.extend([token for token in tokens if token.startswith('@')])\n",
    "    \n",
    "print(\"User Mentions:\", users)"
   ],
   "id": "fe288d453338dbcd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Mentions: ['@user1', '@user2', '@user3', '@user4']\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T07:54:17.781496Z",
     "start_time": "2024-06-16T07:54:17.777995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "cases = [\n",
    "    \"Check out the new product at https://example.com! #newproduct @example_user 😊\",\n",
    "    \"Visit our website for more details: http://example.org #info\",\n",
    "    \"Don't miss out on the sale! https://sale.example.com #discount\",\n",
    "    \"More updates at https://blog.example.com #tech @example_user\"\n",
    "]\n",
    "\n",
    "\n",
    "urls = []\n",
    "for tweet in cases:\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    urls.extend([token for token in tokens if token.startswith('http') or token.startswith('https')])\n",
    "\n",
    "print(\"URLs:\", urls)\n"
   ],
   "id": "42c8149647518a52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs: ['https://example.com', 'http://example.org', 'https://sale.example.com', 'https://blog.example.com']\n"
     ]
    }
   ],
   "execution_count": 50
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
