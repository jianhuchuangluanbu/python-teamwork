# 使用NLTK和朴素贝叶斯分类器进行推特情感分析

本项目展示了一个使用Python的自然语言处理工具包（NLTK）和朴素贝叶斯分类器的简单情感分析示例。这里使用的数据集是一组带有标签的正面和负面推文。


## 数据加载
第一步是加载数据。我们使用NLTK的twitter_samples模块提供的strings方法来读取包含推文的JSON文件。我们将正面和负面的推文存储在单独的列表中。

## 预处理
接下来，我们定义一个预处理函数来清理我们的推文。这涉及到将文本分词，转换为小写，移除非字母字符，过滤掉那些没有太大意义的常用词（停用词），并将单词还原为其基本形式（词形还原）。

## 数据处理
然后，我们对正面和负面的推文分别应用预处理函数，得到经过处理的标记列表。

## 特征提取
我们合并所有的标记，并使用FreqDist计算每个词汇的出现频率，从而得到词汇及其出现次数的信息。我们将词汇列表转换为一个普通的Python列表，作为模型特征的基础词汇表。

## 提取特征
我们定义一个函数来提取特征。该函数创建一个特征字典，对于基础词汇表中的每个单词，如果在推文标记集合中出现，则将其作为特征添加到字典中。

## 构建标签数据
我们为正面的特征和负面的特征分别构建标签数据，每个特征与其对应的情感标签（正面或负面）配对。

## 合并数据并拆分训练集和测试集
我们将正面和负面的标签数据合并，并使用train_test_split函数将数据拆分为训练集和测试集，其中25%的数据用于测试，75%的数据用于训练。

## 训练模型
我们使用训练数据来训练一个朴素贝叶斯分类器模型。

## 评估模型
最后，我们评估模型的准确率，并打印出来。我们还显示了最具信息性的特征（前10个）。