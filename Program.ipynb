{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-17T04:31:45.374375Z",
     "start_time": "2024-06-17T04:31:40.522761Z"
    }
   },
   "source": [
    "import nltk\n",
    "from nltk.corpus import twitter_samples # nltk自带的语料库，包含推文样本，用于情感分析\n",
    "from nltk.tokenize import word_tokenize # 分词器，字符串分割成单独的词语\n",
    "from nltk.corpus import stopwords   # 停用词，过滤常用词如语气词、连接词等\n",
    "from nltk.stem import WordNetLemmatizer # 词形还原，将词语转变为基本形式\n",
    "import string   # 去标点\n",
    "import itertools    # 迭代器，文本处理中用于展开列表\n",
    "from nltk import FreqDist   # 计算词语或其他元素在文本中出现的频率，统计词频分布\n",
    "from sklearn.model_selection import train_test_split    # 将数据集划分为训练集和测试集，随机分割数据集，保持训练时数据的独立性和随机性\n",
    "from nltk.classify import NaiveBayesClassifier  # 朴素贝叶斯分类器\n",
    "from nltk.classify.util import accuracy as nltk_accuracy    # 计算分类器准确率"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T04:31:48.812854Z",
     "start_time": "2024-06-17T04:31:48.804904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 安装NLTK库：在命令行中运行 pip install nltk\n",
    "# 下载nltk_data:\n",
    "#   import nltk\n",
    "#   nltk.download('twitter_samples')\n",
    "#   nltk.download('punkt')\n",
    "#   nltk.download('stopwords')\n",
    "#   nltk.download('wordnet')\n",
    "# 安装scikit-learn库:在命令行中运行 pip install scikit-learn 或者 pip install -U scikit-learn"
   ],
   "id": "9742012d7cfcca27",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T04:31:49.619257Z",
     "start_time": "2024-06-17T04:31:49.608086Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fb69f251bbb55532",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-17T04:31:50.465698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 下载必要的资源\n",
    "nltk.download('twitter_samples')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# 加载数据\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')   # strings方法读取文件，并返回一个包含所有正面推文的列表，每条推文作为列表中的一个字符串元素.结果赋值给一个字符串列表\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')   # 负面\n",
    "\n",
    "# 预处理函数\n",
    "stop_words = set(stopwords.words('english'))    #在 twitter上下载的推文样本是英文，因此停用词处理选择对英文进行处理，过滤像‘is’、’and‘、’the‘这类词语\n",
    "lemmatizer = WordNetLemmatizer()    # 将词语进行还原为基本形式，’doing‘->'do'。\n",
    "\n",
    "\n",
    "# 对推文进行预处理\n",
    "def preprocess_tweet(tweet):\n",
    "    tokens = word_tokenize(tweet)\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha()] #转换成小写且仅保留字母\n",
    "    tokens = [token for token in tokens if token not in stop_words] #去除停用词\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]  #词形还原\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# 处理数据\n",
    "positive_tokens = [preprocess_tweet(tweet) for tweet in positive_tweets]\n",
    "negative_tokens = [preprocess_tweet(tweet) for tweet in negative_tweets]\n",
    "\n",
    "# 特征提取\n",
    "all_tokens = list(itertools.chain(*positive_tokens)) + list(itertools.chain(*negative_tokens))\n",
    "freq_dist = FreqDist(all_tokens)    # 计算列表中每个词汇的出现频率，并赋值给freq_dist,获取词汇及其出现次数的信息\n",
    "vocab = list(freq_dist.keys())  # 将词汇列表转换为一个普通的Python列表\n",
    "\n",
    "# vocab即为经过处理得到的模型特征的基础词汇表\n",
    "\n",
    "# 提取特征\n",
    "def extract_features(tokens):\n",
    "    features = {}   # 创建特征字典\n",
    "    token_set = set(tokens)\n",
    "    for word in vocab:\n",
    "        features[word] = (word in token_set)\n",
    "    return features\n",
    "\n",
    "\n",
    "positive_features = [extract_features(tokens) for tokens in positive_tokens]\n",
    "negative_features = [extract_features(tokens) for tokens in negative_tokens]\n",
    "\n",
    "# 构建标签数据\n",
    "positive_labels = [(feature, 'positive') for feature in positive_features]\n",
    "negative_labels = [(feature, 'negative') for feature in negative_features]\n",
    "\n",
    "# 合并数据并拆分训练集和测试集\n",
    "dataset = positive_labels + negative_labels\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.25)   # 25%作为测试集，75%作为训练集\n",
    "\n",
    "# 训练模型\n",
    "model = NaiveBayesClassifier.train(train_data)\n",
    "\n",
    "# 评估模型\n",
    "print(f\"Accuracy: {nltk_accuracy(model, test_data):.2f}\")   # 输出测试集准确率\n",
    "model.show_most_informative_features(10)    # 显示最具信息性的特征（前10个）\n",
    "\n",
    "\n",
    "'''\n",
    "'''\n"
   ],
   "id": "2effd4d0fda5a7be",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\31542\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\31542\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\31542\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\31542\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "46a8d502a37fc9f1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
